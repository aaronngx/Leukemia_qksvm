#!/usr/bin/env python3
"""
Data Loading Utility for Preprocessed Gene Expression Data

Provides unified interface for loading preprocessed data from feature selection:
- Auto-detects label column names ("cancer" or "label")
- Converts labels to binary format (ALL → 0, AML → 1)
- Discovers available preprocessed files in results/ directory
- Supports train/test split, CV folds, and independent validation sets
"""

import numpy as np
import pandas as pd
from pathlib import Path
from typing import Union, Tuple, Dict, List, Optional


def get_label_mapping() -> dict:
    """
    Return label mapping for leukemia classification.

    Returns:
        dict: Mapping {'ALL': 0, 'AML': 1}
    """
    return {'ALL': 0, 'AML': 1}


def _detect_label_column(df: pd.DataFrame) -> str:
    """
    Auto-detect label column name in dataframe.

    Args:
        df: DataFrame to search

    Returns:
        str: Column name ('label' or 'cancer')

    Raises:
        ValueError: If no label column found
    """
    if 'label' in df.columns:
        return 'label'
    elif 'cancer' in df.columns:
        return 'cancer'
    else:
        raise ValueError(
            "No label column found in data. "
            "Expected 'label' or 'cancer' column. "
            f"Available columns: {list(df.columns)}"
        )


def _convert_labels(labels: pd.Series) -> np.ndarray:
    """
    Convert string labels to binary format: ALL → 0, AML → 1.

    Args:
        labels: Series with 'ALL'/'AML' labels or numeric labels

    Returns:
        np.ndarray: Binary labels (0 for ALL, 1 for AML)

    Raises:
        ValueError: If labels contain unexpected values
    """
    if labels.dtype == 'object' or labels.dtype.name == 'category':
        mapping = get_label_mapping()

        # Check for unexpected labels
        unique_labels = set(labels.unique())
        expected_labels = set(mapping.keys())

        if not unique_labels.issubset(expected_labels):
            unexpected = unique_labels - expected_labels
            raise ValueError(
                f"Unexpected label values: {unexpected}. "
                f"Expected only: {expected_labels}"
            )

        return labels.map(mapping).values
    else:
        # Already numeric - verify values are 0 or 1
        unique_vals = set(labels.unique())
        if not unique_vals.issubset({0, 1}):
            raise ValueError(
                f"Numeric labels must be 0 or 1, got: {unique_vals}"
            )
        return labels.values


def load_preprocessed_data(
    file_path: Union[str, Path],
    label_column: Optional[str] = None
) -> Tuple[np.ndarray, np.ndarray]:
    """
    Load preprocessed data from CSV with automatic column detection.

    Automatically detects and handles:
    - Label column name ('cancer' or 'label')
    - Label conversion (ALL → 0, AML → 1)
    - Patient ID column removal

    Args:
        file_path: Path to CSV file
        label_column: Optional explicit label column name (auto-detected if None)

    Returns:
        Tuple[np.ndarray, np.ndarray]:
            - X: Feature matrix (n_samples, n_features)
            - y: Labels (n_samples,) with 0=ALL, 1=AML

    Raises:
        FileNotFoundError: If file doesn't exist
        ValueError: If label column not found or has invalid values

    Example:
        >>> X, y = load_preprocessed_data("results/train_internal_top_16_anova_f.csv")
        >>> print(X.shape)  # (26, 16) - 26 samples, 16 features
        >>> print(np.unique(y))  # [0 1] - binary labels
    """
    file_path = Path(file_path)

    if not file_path.exists():
        raise FileNotFoundError(f"Data file not found: {file_path}")

    # Load CSV
    df = pd.read_csv(file_path)

    # Detect or use specified label column
    if label_column is None:
        label_column = _detect_label_column(df)
    elif label_column not in df.columns:
        raise ValueError(
            f"Specified label column '{label_column}' not found. "
            f"Available columns: {list(df.columns)}"
        )

    # Extract and convert labels
    y = _convert_labels(df[label_column])

    # Get feature columns (exclude label and patient columns)
    exclude_cols = {label_column, 'patient', 'Patient', 'patient_id'}
    feature_cols = [c for c in df.columns if c not in exclude_cols]

    # Extract features
    X = df[feature_cols].values

    return X, y


def discover_preprocessed_files(
    results_dir: Union[str, Path] = "results",
    method: Optional[str] = None,
    genes: Optional[int] = None
) -> Dict[str, Optional[Union[Path, List[Tuple[Path, Path]]]]]:
    """
    Discover available preprocessed data files in results directory.

    Searches for files generated by preprocessing.py:
    - Internal train/test split: train_internal_*, test_internal_*
    - Cross-validation folds: fold_*_train_*, fold_*_test_*
    - Independent test set: independent_*

    Args:
        results_dir: Directory containing preprocessed files
        method: Optional filter by method ('anova' or 'snr')
        genes: Optional filter by number of genes (e.g., 16, 24, 32)

    Returns:
        dict with keys:
            - 'train_internal': Path or None
            - 'test_internal': Path or None
            - 'independent': Path or None
            - 'folds': List[(train_path, test_path)] or None
            - 'method': 'anova' or 'snr' or None
            - 'num_genes': int or None

    Example:
        >>> files = discover_preprocessed_files(method='anova', genes=16)
        >>> if files['train_internal']:
        ...     print(f"Found: {files['train_internal']}")
        ...     X, y = load_preprocessed_data(files['train_internal'])
    """
    results_dir = Path(results_dir)

    if not results_dir.exists():
        return {
            'train_internal': None,
            'test_internal': None,
            'independent': None,
            'folds': None,
            'method': None,
            'num_genes': None
        }

    # Build pattern based on filters
    if method and genes:
        pattern_suffix = f"*_{genes}_*{method}*.csv"
    elif method:
        pattern_suffix = f"*{method}*.csv"
    elif genes:
        pattern_suffix = f"*_{genes}_*.csv"
    else:
        pattern_suffix = "*.csv"

    # Search for train/test split files
    train_internal_files = list(results_dir.glob(f"train_internal_{pattern_suffix}"))
    test_internal_files = list(results_dir.glob(f"test_internal_{pattern_suffix}"))

    # Search for independent files
    independent_files = list(results_dir.glob(f"independent_{pattern_suffix}"))

    # Search for CV fold files
    fold_train_files = sorted(results_dir.glob(f"fold_*_train_{pattern_suffix}"))
    fold_test_files = sorted(results_dir.glob(f"fold_*_test_{pattern_suffix}"))

    # Pair up folds
    folds = None
    if fold_train_files and fold_test_files:
        # Extract fold numbers and pair them
        folds = []
        for train_file in fold_train_files:
            # Extract fold number from filename (e.g., fold_1_train_...)
            fold_num = train_file.stem.split('_')[1]
            # Find corresponding test file
            test_pattern = f"fold_{fold_num}_test_{pattern_suffix}"
            test_files = list(results_dir.glob(test_pattern))
            if test_files:
                folds.append((train_file, test_files[0]))

    # Detect method and gene count from first available file
    detected_method = None
    detected_genes = None

    sample_file = (
        train_internal_files[0] if train_internal_files else
        fold_train_files[0] if fold_train_files else
        independent_files[0] if independent_files else
        None
    )

    if sample_file:
        filename = sample_file.stem

        # Detect method
        if 'anova' in filename.lower():
            detected_method = 'anova'
        elif 'snr' in filename.lower():
            detected_method = 'snr'

        # Detect gene count (look for pattern like "top_16_" or "_16_")
        parts = filename.split('_')
        for i, part in enumerate(parts):
            if part.isdigit() and i > 0 and parts[i-1] in ['top', 'genes']:
                detected_genes = int(part)
                break

    return {
        'train_internal': train_internal_files[0] if train_internal_files else None,
        'test_internal': test_internal_files[0] if test_internal_files else None,
        'independent': independent_files[0] if independent_files else None,
        'folds': folds if folds else None,
        'method': detected_method,
        'num_genes': detected_genes
    }


def print_available_files(
    results_dir: Union[str, Path] = "results",
    method: Optional[str] = None,
    genes: Optional[int] = None
) -> None:
    """
    Print summary of available preprocessed data files.

    Args:
        results_dir: Directory containing preprocessed files
        method: Optional filter by method ('anova' or 'snr')
        genes: Optional filter by number of genes
    """
    files = discover_preprocessed_files(results_dir, method, genes)

    print("\n" + "=" * 60)
    print("AVAILABLE PREPROCESSED DATA")
    print("=" * 60)

    if files['method']:
        print(f"\nMethod: {files['method'].upper()}")
    if files['num_genes']:
        print(f"Genes: {files['num_genes']}")

    if files['train_internal']:
        print(f"\n✓ Internal Train: {files['train_internal'].name}")
        print(f"✓ Internal Test:  {files['test_internal'].name}")

    if files['folds']:
        print(f"\n✓ Cross-Validation: {len(files['folds'])} folds")
        for i, (train, test) in enumerate(files['folds'], 1):
            print(f"  Fold {i}: {train.name} / {test.name}")

    if files['independent']:
        print(f"\n✓ Independent:    {files['independent'].name}")

    if not any([files['train_internal'], files['folds'], files['independent']]):
        print("\n[WARNING] No preprocessed data files found!")
        print(f"Directory: {Path(results_dir).absolute()}")
        print("\nPlease run preprocessing.py first to generate feature-selected data.")

    print()


if __name__ == "__main__":
    """Example usage and testing."""
    print("\n" + "=" * 60)
    print("DATA LOADER UTILITY - EXAMPLE USAGE")
    print("=" * 60)

    # Discover available files
    print_available_files()

    files = discover_preprocessed_files()

    # Try to load data if available
    if files['train_internal']:
        print("\n" + "=" * 60)
        print("LOADING EXAMPLE")
        print("=" * 60)

        print(f"\nLoading: {files['train_internal'].name}")
        X_train, y_train = load_preprocessed_data(files['train_internal'])

        print(f"\nTrain Data:")
        print(f"  Shape: {X_train.shape}")
        print(f"  Features: {X_train.shape[1]}")
        print(f"  Samples: {X_train.shape[0]}")
        print(f"  Class distribution: ALL={sum(y_train==0)}, AML={sum(y_train==1)}")

        if files['test_internal']:
            print(f"\nLoading: {files['test_internal'].name}")
            X_test, y_test = load_preprocessed_data(files['test_internal'])

            print(f"\nTest Data:")
            print(f"  Shape: {X_test.shape}")
            print(f"  Features: {X_test.shape[1]}")
            print(f"  Samples: {X_test.shape[0]}")
            print(f"  Class distribution: ALL={sum(y_test==0)}, AML={sum(y_test==1)}")

        if files['independent']:
            print(f"\nLoading: {files['independent'].name}")
            X_ind, y_ind = load_preprocessed_data(files['independent'])

            print(f"\nIndependent Data:")
            print(f"  Shape: {X_ind.shape}")
            print(f"  Features: {X_ind.shape[1]}")
            print(f"  Samples: {X_ind.shape[0]}")
            print(f"  Class distribution: ALL={sum(y_ind==0)}, AML={sum(y_ind==1)}")

        print("\n✓ Data loading successful!")
    else:
        print("\n[INFO] No preprocessed data found to demonstrate loading.")
        print("Run preprocessing.py first, then try this script again.")

    print()
